import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, Subset
from torchvision import datasets, transforms
from torchvision.utils import save_image
import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import KMeans
from sklearn.metrics import normalized_mutual_info_score as NMI
# æ³¨æ„: ä½ çš„ evaluate_model ä¾èµ– linear_sum_assignmentï¼Œè¿™é€šå¸¸éœ€è¦ scipyã€‚
# å¦‚æœä½ æ²¡æœ‰å®‰è£… scipyï¼Œevaluate_model å¯èƒ½ä¼šå¤±è´¥ã€‚
# ä¸ºäº†ä¿æŒä»£ç å®Œæ•´æ€§ï¼Œæˆ‘åœ¨è¿™é‡Œä¸å¯¼å…¥å®ƒï¼Œä½†è¯·ç¡®ä¿åœ¨è¿è¡Œæ—¶ç¯å¢ƒä¸­æœ‰å®ƒã€‚
# from scipy.optimize import linear_sum_assignment 

# -----------------------------------------------------
# A. é…ç½®ç±»
# -----------------------------------------------------

class Config:
    """
    mDPM_SemiSup æ¨¡å‹çš„é…ç½®å‚æ•°
    """
    def __init__(self):
        # ---------------------
        # è®­ç»ƒå’Œç¡¬ä»¶è®¾ç½®
        # ---------------------
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.output_dir = "./mDPM_sup"
        self.batch_size = 128
        self.final_epochs = 50 
        self.optuna_epochs = 10 
        self.lr = 2e-4                    # å­¦ä¹ ç‡
        self.labeled_per_class = 100      # æ¯ç±»ç”¨äºç›‘ç£å­¦ä¹ çš„æ ·æœ¬æ•° (åŠç›‘ç£)
        
        # ---------------------
        # PVEM æ¡†æ¶æƒé‡ (ç”¨äºæ— ç›‘ç£æŸå¤±)
        # ---------------------
        # self.beta = 1.0                   # KL æ•£åº¦æƒé‡ (VAEçš„zå·²ç§»é™¤ï¼Œæ­¤å‚æ•°å¯è§†ä¸º 0 æˆ–ç”¨äºå…¶ä»–æ­£åˆ™åŒ–)
        self.alpha_unlabeled = 1        # æ— æ ‡ç­¾æ•°æ®æŸå¤±çš„æƒé‡
        self.lambda_entropy = 5.0         # ç†µæƒ©ç½šé¡¹çš„æƒé‡ (é¼“åŠ± q(x|x0) è½¯åˆ†é…)
        
        # ---------------------
        # Gumbel Softmax é€€ç«å‚æ•° (ç”¨äºç¦»æ•£æ½œåœ¨å˜é‡ x çš„æ¨ç†)
        # ---------------------
        self.initial_gumbel_temp = 1.0    # Gumbel Softmax åˆå§‹æ¸©åº¦ (tau)
        self.min_gumbel_temp = 0.1        # Gumbel Softmax æœ€å°æ¸©åº¦
        self.gumbel_anneal_rate = 0.995   # æ¯ epoch çš„é€€ç«ç‡
        self.current_gumbel_temp = self.initial_gumbel_temp # å½“å‰æ¸©åº¦
        
        # ---------------------
        # æ¨¡å‹ç»“æ„å’Œ DPM å‚æ•°
        # ---------------------
        self.latent_dim = 0               # è¿ç»­æ½œåœ¨å˜é‡ z å·²ç§»é™¤/ç®€åŒ–ï¼Œè®¾ä¸º 0
        self.num_classes = 10             # ç¦»æ•£æ½œåœ¨å˜é‡ x çš„ç±»åˆ«æ•° (ä¾‹å¦‚ MNIST)
        
        # DPM ç‰¹æœ‰å‚æ•°
        self.timesteps = 1000             # æ‰©æ•£æ€»æ—¶é—´æ­¥ T
        self.image_channels = 1           # è¾“å…¥å›¾åƒé€šé“æ•° (ä¾‹å¦‚ MNIST æ˜¯ 1)
        
        # ConditionalUnet/DPM å‚æ•°
        self.unet_base_channels = 64      # U-Net åˆå§‹é€šé“æ•°
        self.unet_time_emb_dim = 256      # æ—¶é—´å’Œç±»åˆ«åµŒå…¥ç»´åº¦
        
        # åœ¨å®é™…è®­ç»ƒä¸­ï¼Œéœ€è¦ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(self.output_dir, exist_ok=True)

# -----------------------------------------------------
# B. DPM å‰å‘è¿‡ç¨‹
# -----------------------------------------------------

class DPMForwardProcess(nn.Module):
    """
    DDPM æ‰©æ•£å‰å‘è¿‡ç¨‹ï¼šå®šä¹‰ Î²t, Î±t ç­‰å‚æ•°ï¼Œå¹¶å®ç° q(x_t | x_0) çš„é‡‡æ ·ã€‚
    """
    def __init__(self, timesteps: int = 1000, schedule: str = 'linear'):
        super().__init__()
        self.timesteps = timesteps

        # å®šä¹‰ Î² è°ƒåº¦
        if schedule == 'linear':
            # ä» 1e-4 åˆ° 0.02 çš„çº¿æ€§è°ƒåº¦
            self.register_buffer('betas', torch.linspace(1e-4, 0.02, timesteps))
        else:
            raise NotImplementedError(f"Schedule {schedule} not implemented.")

        # è®¡ç®— Î± å‚æ•°
        self.register_buffer('alphas', 1.0 - self.betas)
        self.register_buffer('alphas_cumprod', torch.cumprod(self.alphas, dim=0))
        self.register_buffer('sqrt_alphas_cumprod', torch.sqrt(self.alphas_cumprod))
        self.register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1.0 - self.alphas_cumprod))

    def q_sample(self, x_0, t, noise=None):
        """
        æ ¹æ® q(x_t | x_0) = N(x_t; sqrt(alpha_bar_t) * x_0, (1 - alpha_bar_t) * I) é‡‡æ · x_tã€‚
        """
        if noise is None:
            noise = torch.randn_like(x_0)

        # æå–å¯¹åº”æ—¶é—´æ­¥ t çš„å‚æ•°
        # ç¡®ä¿å½¢çŠ¶åŒ¹é…ï¼š(B,) -> (B, 1, 1, 1)
        sqrt_alphas_cumprod_t = self._extract_t(self.sqrt_alphas_cumprod, t, x_0.shape)
        sqrt_one_minus_alphas_cumprod_t = self._extract_t(self.sqrt_one_minus_alphas_cumprod, t, x_0.shape)

        # x_t = sqrt(alpha_bar_t) * x_0 + sqrt(1 - alpha_bar_t) * noise
        x_t = sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise
        
        return x_t

    def _extract_t(self, a, t, x_shape):
        """
        ä»å‚æ•°å¼ é‡ a ä¸­æå–å¯¹åº”æ—¶é—´æ­¥ t çš„å€¼ï¼Œå¹¶é‡å¡‘ä»¥åŒ¹é… x_shapeã€‚
        """
        batch_size = t.shape[0]
        # ä½¿ç”¨ t.to(a.device) ç¡®ä¿ç´¢å¼•å’Œå¼ é‡åœ¨åŒä¸€è®¾å¤‡ä¸Š
        out = a.gather(-1, t.to(a.device)) 
        # é‡å¡‘ï¼š (B,) -> (B, 1, 1, 1)
        return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)

# -----------------------------------------------------
# C. U-Net ç»„ä»¶
# -----------------------------------------------------

class SinusoidalPositionalEmbedding(nn.Module):
    """
    æ—¶é—´æ­¥ t çš„æ­£å¼¦ä½ç½®åµŒå…¥ (Time Step t)
    """
    def __init__(self, dim):
        super().__init__()
        self.dim = dim

    def forward(self, t):
        device = t.device
        half_dim = self.dim // 2
        # è®¡ç®— log(10000) / (dim/2 - 1)
        embeddings = torch.log(torch.tensor(10000.0, device=device)) / (half_dim - 1)
        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)
        embeddings = t.float().unsqueeze(1) * embeddings.unsqueeze(0)
        embeddings = torch.cat([torch.sin(embeddings), torch.cos(embeddings)], dim=-1)
        return embeddings


class ResidualBlock(nn.Module):
    """
    å¸¦æ—¶é—´æ­¥æ¡ä»¶æ³¨å…¥çš„æ®‹å·®å—ã€‚
    ç¡®ä¿æ‰€æœ‰ 3x3 å·ç§¯ä½¿ç”¨ padding=1ï¼Œä»¥ä¿æŒç©ºé—´å°ºå¯¸ä¸å˜ã€‚
    """
    def __init__(self, in_channels, out_channels, time_embed_dim, kernel_size=3):
        super().__init__()
        
        # ç¡®ä¿ padding è¢«æ­£ç¡®è®¾ç½® (å¯¹äº kernel_size=3, padding=1)
        padding = kernel_size // 2
        
        # 1. ä¸»è·¯å¾„ (Conv -> GroupNorm -> SiLU)
        # ä½¿ç”¨ padding=padding ç¡®ä¿è¾“å…¥å’Œè¾“å‡ºçš„ H/W å°ºå¯¸ä¸€è‡´
        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=padding)
        self.norm1 = nn.GroupNorm(8, out_channels)
        self.act1 = nn.SiLU()
        
        # 2. ç¬¬äºŒå±‚ (Conv -> GroupNorm -> SiLU)
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, padding=padding)
        self.norm2 = nn.GroupNorm(8, out_channels)
        self.act2 = nn.SiLU()
        
        # 3. æ—¶é—´åµŒå…¥æŠ•å½±å±‚
        self.time_mlp = nn.Linear(time_embed_dim, out_channels)
        
        # 4. æ®‹å·®è·³è·ƒè¿æ¥ (å¦‚æœé€šé“æ•°ä¸åŒ¹é…åˆ™è¿›è¡Œ 1x1 å·ç§¯)
        self.residual_conv = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()

    def forward(self, x, t_emb):
        """
        Args:
            x (Tensor): è¾“å…¥ç‰¹å¾å›¾ (B, C_in, H, W)
            t_emb (Tensor): æ—¶é—´å’Œç±»åˆ«è”åˆåµŒå…¥ (B, time_embed_dim)
            
        Returns:
            Tensor: è¾“å‡ºç‰¹å¾å›¾ (B, C_out, H, W)
        """
        # 1. ç¬¬ä¸€å±‚å·ç§¯å’Œæ¿€æ´»
        h = self.conv1(x)
        h = self.act1(self.norm1(h))
        
        # 2. æ³¨å…¥æ—¶é—´æ¡ä»¶
        # å°† (B, time_embed_dim) å½¢çŠ¶çš„ t_emb æŠ•å½±å¹¶é‡å¡‘ä¸º (B, C_out, 1, 1)ï¼Œä»¥ä¾¿é€šè¿‡å¹¿æ’­è¿›è¡ŒåŠ æ³•
        time_emb_projected = self.time_mlp(t_emb)[:, :, None, None] 
        h = h + time_emb_projected
        
        # 3. ç¬¬äºŒå±‚å·ç§¯å’Œå½’ä¸€åŒ–
        h = self.conv2(h)
        h = self.norm2(h)
        
        # 4. æ®‹å·®è¿æ¥: h + x
        # æ³¨æ„: residual_conv(x) ç¡®ä¿ x çš„é€šé“æ•°åŒ¹é… h çš„é€šé“æ•°
        return self.act2(h + self.residual_conv(x))

# ç´§æ¥åœ¨ ResidualBlock(nn.Module) å®šä¹‰ä¹‹å
# --- ResidualBlock Sanity Check ---
try:
    temp_block = ResidualBlock(in_channels=32, out_channels=32, time_embed_dim=256)
    temp_x = torch.randn(2, 32, 28, 28)
    temp_t = torch.randn(2, 256)
    temp_out = temp_block(temp_x, temp_t)
    assert temp_out.shape[2] == 28 and temp_out.shape[3] == 28, \
        f"ResidualBlock is shrinking the image! Input 28x28, Output {temp_out.shape[2]}x{temp_out.shape[3]}"
    print("ResidualBlock check: PASS (Size kept).")
except AssertionError as e:
    print(f"ResidualBlock check: FAILED! {e}")
    # å¼ºåˆ¶é€€å‡ºï¼Œå› ä¸ºè¿™æ˜¯æœ€å¯èƒ½çš„åŸå› 
    import sys; sys.exit(1)
except Exception as e:
    print(f"ResidualBlock check: ERROR! {e}")
# -----------------------------------

import torch
import torch.nn as nn
import torch.nn.functional as F

class AttentionBlock(nn.Module):
    """
    è‡ªæ³¨æ„åŠ›å—ã€‚
    ä½¿ç”¨ 1x1 å·ç§¯ï¼ˆkernel=1, padding=0ï¼‰ç¡®ä¿ç©ºé—´å°ºå¯¸ä¿æŒä¸å˜ã€‚
    """
    def __init__(self, channels):
        super().__init__()
        self.norm = nn.GroupNorm(8, channels)
        
        # å¼ºåˆ¶ä½¿ç”¨ padding=0 ä¸” kernel_size=1
        self.qkv = nn.Conv2d(channels, channels * 3, kernel_size=1, padding=0, bias=False)
        self.proj_out = nn.Conv2d(channels, channels, kernel_size=1, padding=0)

    def forward(self, x, cond_emb=None):
        # æ·»åŠ cond_embå‚æ•°ä½†ä¸ä½¿ç”¨å®ƒï¼Œä»¥å…¼å®¹U-Netä¸­çš„ç»Ÿä¸€è°ƒç”¨æ–¹å¼
        h = self.norm(x)
        q, k, v = self.qkv(h).chunk(3, dim=1) # (B, C, H, W)
        
        # å°†ç©ºé—´ç»´åº¦åˆå¹¶åˆ° batch ç»´åº¦è¿›è¡ŒçŸ©é˜µä¹˜æ³•
        q = q.flatten(2).transpose(1, 2) # (B, H*W, C)
        k = k.flatten(2)                # (B, C, H*W)
        v = v.flatten(2).transpose(1, 2) # (B, H*W, C)
        
        # Scaled Dot-Product Attention
        attn = (q @ k) * (q.shape[-1] ** -0.5)
        attn = F.softmax(attn, dim=-1)
        
        out = attn @ v                  # (B, H*W, C)
        out = out.transpose(1, 2).reshape(x.shape) # è¿˜åŸå› (B, C, H, W)
        
        return x + self.proj_out(out) # æ®‹å·®è¿æ¥

class ConditionalUnet(nn.Module):
    """
    Conditional U-Net (ä¿®å¤äº† nn.Sequential å¯¼è‡´çš„æ¡ä»¶ä¼ é€’é”™è¯¯).
    - ä½¿ç”¨ nn.ModuleList åµŒå¥—ç»“æ„ï¼Œåœ¨ forward ä¸­æ‰‹åŠ¨æ§åˆ¶ cond_emb ä¼ é€’ã€‚
    """
    def __init__(self, in_channels=1, base_channels=64, num_classes=10, time_emb_dim=256):
        super().__init__()
        self.time_emb_dim = time_emb_dim
        self.num_classes = num_classes

        # time and label embeddings
        self.time_mlp = nn.Sequential(
            SinusoidalPositionalEmbedding(time_emb_dim),
            nn.Linear(time_emb_dim, time_emb_dim),
            nn.SiLU(),
            nn.Linear(time_emb_dim, time_emb_dim),
        )
        self.label_emb = nn.Embedding(num_classes, time_emb_dim)

        # channels configuration: ch0=64, ch1=128, ch2=256, ch3=512
        # âš ï¸ ä¿®æ­£ï¼šåªä½¿ç”¨ 3 ä¸ªé€šé“ç­‰çº§ï¼Œch0=64, ch1=128, ch2=256 (Bottleneck size)
        ch = [base_channels, base_channels * 2, base_channels * 4] 
        
        # initial conv
        self.init_conv = nn.Conv2d(in_channels, ch[0], 3, padding=1)

        # Encoder blocks (Down-sampling steps) - åªæœ‰ 2 ä¸ª Down Stages
        self.downs = nn.ModuleList([
            nn.ModuleList([ # Stage 1: 28x28 -> 14x14
                ResidualBlock(ch[0], ch[0], time_emb_dim),
                ResidualBlock(ch[0], ch[1], time_emb_dim), 
                nn.MaxPool2d(2)
            ]),
            nn.ModuleList([ # Stage 2: 14x14 -> 7x7 (Bottleneck Input)
                ResidualBlock(ch[1], ch[2], time_emb_dim), 
                AttentionBlock(ch[2]),
                nn.MaxPool2d(2) # âš ï¸ ä¿®æ­£ï¼šè¿™æ˜¯æœ€åä¸€ä¸ª MaxPool
            ]),
            # ç§»é™¤ç¬¬ä¸‰ä¸ª Down Stage
        ])

        # Bottleneck (ç°åœ¨åœ¨ 7x7 ä¸Šè¿è¡Œ)
        self.bottleneck = nn.ModuleList([
            ResidualBlock(ch[2], ch[2], time_emb_dim),
            AttentionBlock(ch[2]),
            ResidualBlock(ch[2], ch[2], time_emb_dim),
        ])

        # Decoder blocks (Up-sampling steps) - åªæœ‰ 2 ä¸ª Up Stages
        self.ups = nn.ModuleList([
            nn.ModuleList([ # Stage 1 Up: 7x7 -> 14x14
                ResidualBlock(ch[2] + ch[1], ch[1], time_emb_dim), # Concat ch[2]+ch[1] -> ch[1]
                AttentionBlock(ch[1])
            ]),
            nn.ModuleList([ # Stage 2 Up: 14x14 -> 28x28
                ResidualBlock(ch[1] + ch[0], ch[0], time_emb_dim), # Concat ch[1]+ch[0] -> ch[0]
            ]),
            # ç§»é™¤ç¬¬ä¸‰ä¸ª Up Stage
        ])
        self.upsample = nn.Upsample(scale_factor=2, mode='nearest')

        # final conv
        self.final_conv = nn.Sequential(
            nn.GroupNorm(8, ch[0]),
            nn.SiLU(),
            nn.Conv2d(ch[0], in_channels, 3, padding=1)
        )

    def forward(self, x, t, y_cond):
        """
        x: (B, C, H, W)
        t: (B,) long
        y_cond: LongTensor (B,) or FloatTensor (B, num_classes)
        """
        # embed time and label
        t_emb = self.time_mlp(t)
        if y_cond.dim() == 2 and y_cond.size(1) == self.num_classes:
            # è½¯æ ‡ç­¾/æ¦‚ç‡è¾“å…¥ï¼Œè¿›è¡ŒçŸ©é˜µä¹˜æ³•å¾—åˆ°åµŒå…¥
            y_emb = y_cond @ self.label_emb.weight
        elif y_cond.dim() == 1 and y_cond.dtype == torch.long:
            # ç¡¬æ ‡ç­¾ç´¢å¼•è¾“å…¥ï¼Œè¿›è¡Œ Embedding æŸ¥æ‰¾
            y_emb = self.label_emb(y_cond)
        else:
            raise ValueError("y_cond å¿…é¡»æ˜¯ LongTensor ç´¢å¼• (B) æˆ– FloatTensor æ¦‚ç‡ (B x C)ã€‚")
        cond_emb = t_emb + y_emb

        # initial conv
        x = self.init_conv(x)
        
        # Encoder (ä¿å­˜è·³è·ƒè¿æ¥)
        skips = [x] 
        
        # âš ï¸ æ³¨æ„: ç§»é™¤çš„ debug ä»£ç ï¼Œé¿å…å¹²æ‰°
        for stage_idx, down_block_set in enumerate(self.downs):
            for module in down_block_set:
                if isinstance(module, (ResidualBlock, AttentionBlock)):
                    x = module(x, cond_emb)
                else:
                    x = module(x)
            
            # æ£€æŸ¥ MaxPool åçš„å°ºå¯¸æ˜¯å¦æ­£ç¡®ï¼ˆ14x14 æˆ– 7x7ï¼‰
            skips.append(x)
            
        skips.pop() # ç§»é™¤æœ€åä¸€ä¸ª down-sample çš„è¾“å‡º (å®ƒå°†è¿›å…¥ Bottleneck)
        
        # Bottleneck
        for block in self.bottleneck:
            x = block(x, cond_emb)

        # Decoder (åå‘ä½¿ç”¨è·³è·ƒè¿æ¥)
        for up_block_set, skip in zip(self.ups, reversed(skips)):
            
            # 1. Upsample: 7->14, 14->28ã€‚æ‰€æœ‰å°ºå¯¸å‡ä¸º 2 çš„å¹‚æ¬¡æ–¹ï¼Œå› æ­¤ Upsample å®Œç¾å¯¹é½ã€‚
            x = self.upsample(x)
            
            # 2. Safety Align/Concat Skip: ç†è®ºä¸Š x.shape == skip.shape
            if x.shape[2] != skip.shape[2] or x.shape[3] != skip.shape[3]:
                 # âš ï¸ ç†è®ºä¸Šæ­¤è£å‰ªä¸å†å‘ç”Ÿï¼Œä½†ä¿ç•™ä½œä¸ºå®‰å…¨æªæ–½
                 skip = skip[:, :, :x.shape[2], :x.shape[3]] 
            x = torch.cat([x, skip], dim=1) 
            
            # 3. Apply Up Blocks 
            for module in up_block_set:
                if isinstance(module, (ResidualBlock, AttentionBlock)):
                    x = module(x, cond_emb)
                else:
                    x = module(x) 

        # final conv
        out = self.final_conv(x)

        return out

# -----------------------------------------------------
# D. è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
# -----------------------------------------------------

def gumbel_softmax_sample(logits, temperature):
    """è®¡ç®— Gumbel Softmax è½¯åˆ†é…."""
    noise = torch.rand_like(logits)
    gumbel = -torch.log(-torch.log(noise + 1e-9) + 1e-9)
    return F.softmax((logits + gumbel) / (temperature + 1e-9), dim=-1)

def get_mnist_loader(batch_size=128, train=True, shuffle=True, download=True):
    """æ ‡å‡†çš„ MNIST DataLoader."""
    ds = datasets.MNIST('./data', train=train, download=download, transform=transforms.ToTensor())
    return DataLoader(ds, batch_size=batch_size, shuffle=shuffle, num_workers=2, pin_memory=True)

def plot_training_curves(metrics, outpath):
    """ç»˜åˆ¶è®­ç»ƒæŒ‡æ ‡æ›²çº¿ (å·²é€‚é… mDPM æŒ‡æ ‡)ã€‚"""
    plt.figure(figsize=(12, 5))
    
    # æŸå¤±å’Œ ELBO (å·¦ä¾§ Y è½´)
    ax1 = plt.gca()
    if "Neg_ELBO" in metrics: ax1.plot(metrics["Neg_ELBO"], label="-ELBO", color='tab:blue')
    if "DPM_Loss" in metrics: ax1.plot(metrics["DPM_Loss"], label="DPM Loss", color='tab:orange')
    ax1.set_ylabel("Loss / -ELBO")
    ax1.tick_params(axis='y', labelcolor='tab:blue')
    ax1.legend(loc='upper left')

    # å‡†ç¡®ç‡å’Œ NMI (å³ä¾§ Y è½´)
    ax2 = ax1.twinx()
    if "NMI" in metrics: ax2.plot(metrics["NMI"], label="NMI", color='tab:green', linestyle='--')
    if "PosteriorAcc" in metrics: ax2.plot(metrics["PosteriorAcc"], label="Acc", color='tab:red', linestyle='--')
    ax2.set_ylabel("Accuracy / NMI")
    ax2.tick_params(axis='y', labelcolor='tab:red')
    ax2.legend(loc='upper right')
    
    plt.xlabel("Epoch"); plt.title("mDPM Training Metrics")
    plt.grid(True); plt.tight_layout()
    plt.savefig(outpath)
    plt.close()

# =====================================================
# E. æ•°æ®åŠ è½½è¾…åŠ©å‡½æ•° (Semi-supervised Loader) (ä¿æŒä¸å˜)
# =====================================================

def get_semi_loaders(cfg, labeled_per_class=100):
    """åˆ›å»ºåŠç›‘ç£å­¦ä¹ æ‰€éœ€çš„ labeled, unlabeled, å’Œ val loaders."""
    dataset = datasets.MNIST('./data', train=True, download=True, transform=transforms.ToTensor())
    labels = np.array(dataset.targets)
    labeled_idx, unlabeled_idx = [], []
    for c in range(cfg.num_classes):
        idx_c = np.where(labels == c)[0]
        count = min(labeled_per_class, len(idx_c))
        labeled_idx.extend(idx_c[:count])
        unlabeled_idx.extend(idx_c[count:])
        
    labeled_set = Subset(dataset, labeled_idx)
    unlabeled_set = Subset(dataset, unlabeled_idx)
    
    # ä½¿ç”¨è®­ç»ƒé›†çš„å‰ 10% ä½œä¸ºéªŒè¯é›†
    full_train_indices = list(range(len(dataset)))
    val_indices = full_train_indices[:int(0.1 * len(dataset))]
    val_set = Subset(dataset, val_indices)
    
    labeled_loader = DataLoader(labeled_set, batch_size=cfg.batch_size, shuffle=True)
    unlabeled_loader = DataLoader(unlabeled_set, batch_size=cfg.batch_size, shuffle=True)
    val_loader = DataLoader(val_set, batch_size=cfg.batch_size, shuffle=False)
    return labeled_loader, unlabeled_loader, val_loader

# =====================================================
# F. æ€§èƒ½è¯„ä¼° (DPM åéªŒå‡†ç¡®ç‡) (ä¿æŒä¸å˜ï¼Œä½†éœ€è¦ scipy.optimize.linear_sum_assignment)
# =====================================================

def evaluate_model(model, loader, cfg):
    """
    è®¡ç®—åéªŒèšç±»æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾çš„å¯¹é½å‡†ç¡®ç‡å’Œ NMIï¼Œä½¿ç”¨ DPM æŸå¤±ä½œä¸ºè´Ÿå¯¹æ•°ä¼¼ç„¶çš„ä»£ç†ã€‚
    è¿”å›: posterior_acc, cluster2label, nmi
    """
    # âš ï¸ æ³¨æ„: æ­¤å‡½æ•°éœ€è¦ä» scipy.optimize å¯¼å…¥ linear_sum_assignment
    try:
        from scipy.optimize import linear_sum_assignment
    except ImportError:
        print("WARNING: linear_sum_assignment from scipy not found. Returning 0 for Acc.")
        return 0.0, {}, 0.0 # æ— æ³•è®¡ç®—å‡†ç¡®ç‡

    model.eval()
    preds, ys_true = [], []
    
    # ä½¿ç”¨å›ºå®šçš„ t ä½œä¸ºè¯„ä¼°æ—¶é—´æ­¥ (ä¾‹å¦‚æ€»æ—¶é—´æ­¥çš„ä¸€åŠ)
    t_eval_val = cfg.timesteps // 2
    
    with torch.no_grad():
        for x_0, y_true in loader:
            x_0 = x_0.to(cfg.device)
            batch_size = x_0.size(0)
            
            # Monte Carlo ä¼°è®¡ï¼šé‡‡æ ·å™ªå£°
            current_noise = torch.randn_like(x_0)
            current_t = torch.full((batch_size,), t_eval_val, device=cfg.device, dtype=torch.long)
            x_t = DPMForwardProcess(cfg.timesteps).q_sample(x_0, current_t, current_noise) # éœ€è¦å®ä¾‹åŒ– DPMForwardProcess æˆ–å°†å…¶ä½œä¸ºæ¨¡å‹çš„ä¸€éƒ¨åˆ†
            
            # å‡è®¾ model.registered_pi å­˜åœ¨å¹¶å·²åˆå§‹åŒ–
            log_pi = torch.log(torch.ones(cfg.num_classes) / cfg.num_classes + 1e-8).unsqueeze(0).to(x_0.device)
            dpm_loss_proxies = []

            for k in range(cfg.num_classes):
                y_label_k = torch.full((batch_size,), k, device=x_0.device).long()
                
                # è®¡ç®—æ¡ä»¶ DPM æŸå¤± L_t(k)
                pred_noise_k = model.cond_denoiser(x_t, current_t, y_label_k)
                dpm_loss_k = F.mse_loss(pred_noise_k, current_noise, reduction='none').view(batch_size, -1).mean(dim=1)
                
                # log P(x_0|x=k) proxy
                dpm_loss_proxies.append(-dpm_loss_k.unsqueeze(1))
            
            logits = torch.cat(dpm_loss_proxies, dim=1) + log_pi
            pred_cluster = torch.argmax(logits, dim=1).cpu().numpy()
            preds.append(pred_cluster)
            ys_true.append(y_true.numpy())

    preds = np.concatenate(preds)
    ys_true = np.concatenate(ys_true)
    n_classes = cfg.num_classes
    
    # 1. è®¡ç®— NMI
    nmi = NMI(ys_true, preds) 

    # 2. è®¡ç®—å‡†ç¡®ç‡ (Alignment Calculation using Hungarian Algorithm)
    cost_matrix = np.zeros((n_classes, n_classes))
    for i in range(n_classes): 
        for j in range(n_classes): 
            cost_matrix[i, j] = -np.sum((ys_true == i) & (preds == j))
            
    row_ind, col_ind = linear_sum_assignment(cost_matrix)
    cluster2label = {int(c): int(l) for c, l in zip(col_ind, row_ind)}
    aligned_preds = np.array([cluster2label.get(p, 0) for p in preds])
    posterior_acc = np.mean(aligned_preds == ys_true)
    
    return posterior_acc, cluster2label, nmi

# =====================================================
# G. é‡‡æ ·å’Œå¯è§†åŒ–è¾…åŠ©å‡½æ•° (ä¿æŒä¸å˜)
# =====================================================

def sample_and_save_dpm(denoiser, dpm_process, num_classes, out_path, device, n_per_class=10):
    """
    ä½¿ç”¨ DPM é€†è¿‡ç¨‹ä»å™ªå£° X_T å’Œç±»åˆ«æ¡ä»¶ x ç”Ÿæˆæ ·æœ¬ã€‚
    """
    T = dpm_process.timesteps
    denoiser.eval()

    with torch.no_grad():
        # 1. åˆå§‹åŒ–å™ªå£° x_T
        shape = (n_per_class * num_classes, dpm_process.image_channels, 28, 28)
        x_t = torch.randn(shape, device=device)
        
        # 2. æ„é€ ç±»åˆ«æ¡ä»¶ (ç¡¬æ ‡ç­¾ç´¢å¼•)
        y_cond_idx = torch.arange(num_classes).to(device).repeat_interleave(n_per_class).long()
        
        # ä½¿ç”¨ LongTensor ç´¢å¼•ä½œä¸ºæ¡ä»¶ (ConditionalUnet æ”¯æŒ LongTensor)
        y_cond = y_cond_idx 

        # 3. é€†å‘é‡‡æ ·å¾ªç¯
        for i in reversed(range(1, T)):
            t = torch.full((shape[0],), i, device=device, dtype=torch.long)
            
            # æå–å‚æ•°
            alpha_t = dpm_process._extract_t(dpm_process.alphas, t, shape)
            one_minus_alpha_t_bar = dpm_process._extract_t(dpm_process.sqrt_one_minus_alphas_cumprod, t, shape)
            
            # é¢„æµ‹å™ªå£°
            pred_noise = denoiser(x_t, t, y_cond)
            
            # è®¡ç®—å‡å€¼ mu_t-1 (ä½¿ç”¨ DPM ç†è®ºçš„å»å™ªå…¬å¼)
            mu_t = (x_t - (1 - alpha_t) / one_minus_alpha_t_bar * pred_noise) / alpha_t.sqrt()
            
            # è®¡ç®—æ–¹å·® sigma_t-1 (é€šå¸¸ä¸º beta_t)
            sigma_t = dpm_process._extract_t(dpm_process.betas, t, shape).sqrt()
            
            if i > 1:
                noise = torch.randn_like(x_t)
            else:
                noise = torch.zeros_like(x_t) # æœ€åä¸€ä¸ªæ—¶é—´æ­¥ä¸åŠ å™ªå£°
                
            x_t = mu_t + sigma_t * noise # æ›´æ–° x_{t-1}

        final_samples = x_t.clamp(0, 1) # ç¡®ä¿è¾“å‡ºåœ¨ [0, 1] èŒƒå›´å†…
        save_image(final_samples, out_path, nrow=n_per_class, normalize=True)
    print(f"ğŸ’¾ Saved DPM samples to {out_path}")

def generate_visualizations(model, val_loader, metrics, cfg):
    """ç”Ÿæˆå¹¶ä¿å­˜æœ€ç»ˆå¯è§†åŒ–ç»“æœ (æŒ‡æ ‡æ›²çº¿å’Œæœ€ç»ˆæ ·æœ¬)ã€‚"""
    print("\n--- Generating Final Visualizations ---")
    output_dir = cfg.output_dir
    
    # 1. ç»˜åˆ¶å¹¶ä¿å­˜è®­ç»ƒæŒ‡æ ‡æ›²çº¿
    plot_training_curves(metrics, os.path.join(output_dir, "mDPM_training_metrics.png"))
    print(f"Saved training metrics to {os.path.join(output_dir, 'mDPM_training_metrics.png')}")

    # 2. ç”Ÿæˆå¹¶ä¿å­˜æœ€ç»ˆçš„æ¡ä»¶æ ·æœ¬
    dpm_process = DPMForwardProcess(cfg.timesteps).to(cfg.device) # ä¸´æ—¶å®ä¾‹åŒ–
    sample_and_save_dpm(model.cond_denoiser, dpm_process, cfg.num_classes,
                        os.path.join(output_dir, "mDPM_final_samples.png"), cfg.device)

# -----------------------------------------------------
# H. è¿è¡Œæ—¶çš„å½¢çŠ¶æ£€æŸ¥ (ä½¿ç”¨ä¿®æ­£åçš„ U-Net)
# -----------------------------------------------------

if __name__ == "__main__":
    print("==== Running ConditionalUnet shape check (Fixed) ====")

    # ç¡®ä¿è¿è¡Œç¯å¢ƒä¸­çš„ data ç›®å½•å­˜åœ¨
    os.makedirs('./data', exist_ok=True)
    
    device = "cpu"
    
    # å®ä¾‹åŒ–é…ç½®ï¼Œç”¨äºè·å– DPM å‚æ•°
    cfg = Config()
    
    model = ConditionalUnet(
        in_channels=cfg.image_channels,
        base_channels=32,   # å°ä¸€ç‚¹é€Ÿåº¦æ›´å¿«
        num_classes=cfg.num_classes,
        time_emb_dim=cfg.unet_time_emb_dim
    ).to(device)

    # éšæœºè¾“å…¥ï¼Œç¬¦åˆä½  MNIST çš„ (B=4, C=1, H=28, W=28)
    x = torch.randn(4, 1, 28, 28).to(device)
    t = torch.randint(0, cfg.timesteps, (4,), device=device)
    
    # y_cond å¯ä»¥æ˜¯ one-hot æˆ– long label â€”â€” ä¸¤ä¸ªéƒ½æµ‹
    y_long = torch.randint(0, cfg.num_classes, (4,), device=device)
    y_onehot = F.one_hot(y_long, num_classes=cfg.num_classes).float()

    print("\nTest 1: Using LongTensor labels (y_cond = Long)")
    try:
        out1 = model(x, t, y_long)
        # é¢„æœŸçš„è¾“å‡ºå½¢çŠ¶ï¼š(B, C, H, W)
        expected_shape = torch.Size([4, 1, 28, 28])
        assert out1.shape == expected_shape, f"Expected {expected_shape}, but got {out1.shape}"
        print(" âœ“ Passed. Output shape:", out1.shape)
    except Exception as e:
        print(" âœ— FAILED with LongTensor labels!")
        raise e

    print("\nTest 2: Using one-hot labels (y_cond = Float)")
    try:
        out2 = model(x, t, y_onehot)
        expected_shape = torch.Size([4, 1, 28, 28])
        assert out2.shape == expected_shape, f"Expected {expected_shape}, but got {out2.shape}"
        print(" âœ“ Passed. Output shape:", out2.shape)
    except Exception as e:
        print(" âœ— FAILED with one-hot labels!")
        raise e

    print("\n==== Shape check finished successfully! The ConditionalUnet structure is now correct. ====")