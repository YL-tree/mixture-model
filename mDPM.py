import torch
import torch.nn as nn
import torch.nn.functional as F
# å‡è®¾æ‚¨çš„é¡¹ç›®ä¸­æœ‰ DPM ç›¸å…³çš„ç»„ä»¶
from common_dpm import * # DPMEncoder, ConditionalDPM, DPMForwardProcess, DPMBackwardProcess
import optuna

# -----------------------
# Model Definition (mDPM Adaptation)
# -----------------------
# -----------------------
# Model Definition (mDPM Adaptation - Z simplified to Noise)
# -----------------------
class mDPM_SemiSup(nn.Module):
    def __init__(self, cfg):
        super().__init__()
        # ConditionalDPM åªéœ€è¦æ¡ä»¶ y (ç¦»æ•£æ ‡ç­¾) å’Œæ—¶é—´æ­¥ tã€‚
        self.cond_denoiser = ConditionalUnet(
            in_channels=cfg.image_channels,
            base_channels=cfg.unet_base_channels,
            num_classes=cfg.num_classes,
            time_emb_dim=cfg.unet_time_emb_dim
        )
        self.dpm_process = DPMForwardProcess(cfg.timesteps) 
        self.register_buffer('registered_pi', torch.ones(cfg.num_classes) / cfg.num_classes)
        
    def forward(self, x_0, cfg, y=None):
        batch_size = x_0.size(0)
        
        # Monte Carlo ä¼°è®¡ï¼šé‡‡æ ·æ—¶é—´æ­¥ t å’Œå™ªå£° epsilon (ä¸å†æœ‰ VAE çš„ KL-z)
        t = torch.randint(0, cfg.timesteps, (batch_size,), device=x_0.device).long()
        noise = torch.randn_like(x_0)
        x_t = self.dpm_process.q_sample(x_0, t, noise) # x_t å³ä¸º DPM çš„è¿ç»­æ½œåœ¨å˜é‡
        
        # -------------------
        # ç›‘ç£æ¨¡å¼ (Labeled Data) - ç®€åŒ– C-DPM æŸå¤±
        # -------------------
        if y is not None:
            y_onehot = F.one_hot(y, num_classes=cfg.num_classes).float()
            
            # DPM Loss: L_simple (é¢„æµ‹å™ªå£°ä¸çœŸå®å™ªå£°çš„ L2 æŸå¤±)
            pred_noise = self.cond_denoiser(x_t, t, y_onehot)
            dpm_loss = F.mse_loss(pred_noise, noise, reduction='mean') 
            
            # ç”±äº z è¢«ç®€åŒ–ï¼ŒKL_z = 0ã€‚ total_loss = dpm_loss
            return dpm_loss, -dpm_loss.item(), dpm_loss.item(), 0.0, None, None
            
        # -------------------
        # æ— ç›‘ç£æ¨¡å¼ (Unlabeled Data) - PVEM E/M-Step
        # -------------------
        else:
            log_pi = torch.log(self.registered_pi + 1e-8).unsqueeze(0).to(x_0.device)
            log_lik_proxy = []
            
            # E-Step (è¿‘ä¼¼è®¡ç®— log P(x_0|x=k))
            for k in range(cfg.num_classes):
                y_onehot_k = F.one_hot(torch.full((batch_size,), k, device=x_0.device),
                                       num_classes=cfg.num_classes).float()
                
                # å¯¹æ•°ç©ºé—´å¤šæ­¥è¿‘ä¼¼ & Monte Carlo ä¼°è®¡ï¼šç”¨è´Ÿçš„ L_t ä½œä¸º log lik proxy
                pred_noise_k = self.cond_denoiser(x_t, t, y_onehot_k)
                dpm_loss_k = F.mse_loss(pred_noise_k, noise, reduction='none').view(batch_size, -1).mean(dim=1)
                
                log_p_proxy = -dpm_loss_k # log P(x_0|x=k) ä»£ç†
                log_lik_proxy.append(log_p_proxy.unsqueeze(1))
                
            log_lik_proxy = torch.cat(log_lik_proxy, dim=1)
            logits = log_pi + log_lik_proxy # è¿‘ä¼¼ Log P(x=k|x_0)
            
            # Gumbel Softmax (æ¾å¼› E-Step)
            resp = gumbel_softmax_sample(logits, cfg.current_gumbel_temp)
            
            # M-Step: è®¡ç®—æœŸæœ› DPM æŸå¤± (Recon)
            weighted_dpm_loss = 0.0
            for k in range(cfg.num_classes):
                y_onehot_k = F.one_hot(torch.full((batch_size,), k, device=x_0.device),
                                       num_classes=cfg.num_classes).float()
                
                pred_noise_k = self.cond_denoiser(x_t, t, y_onehot_k)
                dpm_loss_k = F.mse_loss(pred_noise_k, noise, reduction='none').view(batch_size, -1).mean(dim=1)
                
                weighted_dpm_loss += (resp[:, k] * dpm_loss_k).mean()
            
            # ç†µæƒ©ç½š
            entropy = -(resp * torch.log(resp + 1e-8)).sum(dim=1).mean()
            
            # æ€»æŸå¤±ï¼šåŠ æƒçš„ DPM æŸå¤± - ç†µæƒ©ç½š
            total_loss = weighted_dpm_loss - cfg.lambda_entropy * entropy
            
            return total_loss, -total_loss.item(), weighted_dpm_loss.item(), 0.0, resp.detach(), None
# -----------------------
# Posterior Accuracy Evaluation (ä¸ mVAE ç•¥æœ‰ä¸åŒ)
# -----------------------
# -----------------------
# Posterior Accuracy Evaluation 
# -----------------------
def evaluate_model(model, loader, cfg):
    """
    è®¡ç®—åéªŒèšç±»æ ‡ç­¾ä¸çœŸå®æ ‡ç­¾çš„å¯¹é½å‡†ç¡®ç‡å’Œ NMIï¼Œä½¿ç”¨ DPM æŸå¤± L_t ä½œä¸ºè´Ÿå¯¹æ•°ä¼¼ç„¶çš„ä»£ç†ã€‚
    """
    model.eval()
    preds, ys_true = [], []
    
    # ä½¿ç”¨å›ºå®šçš„æ—¶é—´æ­¥ T/2 è¿›è¡Œè¯„ä¼°
    t_eval_val = cfg.timesteps // 2 
    
    with torch.no_grad():
        for x_0, y_true in loader:
            x_0 = x_0.to(cfg.device)
            batch_size = x_0.size(0)
            
            # 1. é‡‡æ · x_t (è¿ç»­æ½œåœ¨å˜é‡)
            current_noise = torch.randn_like(x_0)
            current_t = torch.full((batch_size,), t_eval_val, device=cfg.device, dtype=torch.long)
            x_t = model.dpm_process.q_sample(x_0, current_t, current_noise)
            
            # 2. è®¡ç®—è¿‘ä¼¼ Log P(x|x0)
            log_pi = torch.log(model.registered_pi + 1e-8).unsqueeze(0).to(x_0.device)
            dpm_loss_proxies = [] # -L_t ä»£ç†

            for k in range(cfg.num_classes):
                # æ„é€ ç¡¬æ ‡ç­¾ one-hot å‘é‡ (ç”¨äº ConditinalUnet çš„è¾“å…¥)
                y_onehot_k = F.one_hot(torch.full((batch_size,), k, device=x_0.device),
                                       num_classes=cfg.num_classes).float()
                
                # è®¡ç®—æ¡ä»¶ DPM æŸå¤± L_t(k)
                pred_noise_k = model.cond_denoiser(x_t, current_t, y_onehot_k)
                dpm_loss_k = F.mse_loss(pred_noise_k, current_noise, reduction='none').view(batch_size, -1).mean(dim=1)
                
                # ä½¿ç”¨ -L_t ä½œä¸º log lik proxy
                dpm_loss_proxies.append((-dpm_loss_k).unsqueeze(1))
            
            logits = torch.cat(dpm_loss_proxies, dim=1) + log_pi # è¿‘ä¼¼ Log P(x|x0)
            
            pred_cluster = torch.argmax(logits, dim=1).cpu().numpy()
            preds.append(pred_cluster)
            ys_true.append(y_true.numpy())

    # 3. èšç±»å¯¹é½ (ä½¿ç”¨åŒˆç‰™åˆ©ç®—æ³•)
    preds = np.concatenate(preds)
    ys_true = np.concatenate(ys_true)
    n_classes = cfg.num_classes
    cost_matrix = np.zeros((n_classes, n_classes))
    for i in range(n_classes):
        for j in range(n_classes):
            cost_matrix[i, j] = -np.sum((ys_true == i) & (preds == j))
    row_ind, col_ind = linear_sum_assignment(cost_matrix)
    cluster2label = {int(c): int(l) for c, l in zip(col_ind, row_ind)}
    aligned_preds = np.array([cluster2label.get(p, 0) for p in preds])
    
    # 4. è®¡ç®—æŒ‡æ ‡
    posterior_acc = np.mean(aligned_preds == ys_true)
    nmi = NMI(ys_true, preds)
    
    # è¿”å› Acc, Mapping, NMI
    return posterior_acc, cluster2label, nmi

# =====================================================
# 4. é‡‡æ ·è¿‡ç¨‹ (DPM Backward Process)
# =====================================================
def sample_and_save_dpm(denoiser, dpm_process, num_classes, out_path, device, n_per_class=10):
    """
    ä½¿ç”¨ DPM é€†è¿‡ç¨‹ä»å™ªå£° X_T å’Œç±»åˆ«æ¡ä»¶ x ç”Ÿæˆæ ·æœ¬ã€‚
    """
    T = dpm_process.timesteps
    denoiser.eval()

    with torch.no_grad():
        # 1. åˆå§‹åŒ–å™ªå£° x_T
        shape = (n_per_class * num_classes, dpm_process.image_channels, 28, 28)
        x_t = torch.randn(shape, device=device)
        
        # 2. æ„é€ ç±»åˆ«æ¡ä»¶ (ç¡¬æ ‡ç­¾ç´¢å¼•)
        y_cond = torch.arange(num_classes).to(device).repeat_interleave(n_per_class).long()
        
        # 3. é€†å‘é‡‡æ ·å¾ªç¯ (ä» T-1 è¿­ä»£åˆ° 0)
        for i in reversed(range(1, T)):
            t = torch.full((shape[0],), i, device=device, dtype=torch.long)
            
            # æå–å‚æ•°
            alpha_t = dpm_process._extract_t(dpm_process.alphas, t, shape)
            alpha_bar_t = dpm_process._extract_t(dpm_process.alphas_cumprod, t, shape)
            one_minus_alpha_t_bar = dpm_process._extract_t(dpm_process.sqrt_one_minus_alphas_cumprod, t, shape)
            
            # é¢„æµ‹å™ªå£°
            pred_noise = denoiser(x_t, t, y_cond)
            
            # ä¼°è®¡ x_0 (å¯é€‰ï¼Œç”¨äºæˆªæ–­æˆ–åŠ é€Ÿé‡‡æ ·)
            # pred_x0 = (x_t - pred_noise * one_minus_alpha_t_bar) / alpha_bar_t.sqrt()
            
            # è®¡ç®—å‡å€¼ mu_t-1
            mu_t = (x_t - (1 - alpha_t) / one_minus_alpha_t_bar * pred_noise) / alpha_t.sqrt()
            
            # è®¡ç®—æ–¹å·® sigma_t-1 (é€šå¸¸ä¸º beta_t)
            sigma_t = dpm_process._extract_t(dpm_process.betas, t, shape).sqrt()
            
            if i > 1:
                noise = torch.randn_like(x_t)
            else:
                noise = torch.zeros_like(x_t) # åœ¨æœ€åä¸€æ­¥ä¸åŠ å™ªå£°
                
            x_t = mu_t + sigma_t * noise # æ›´æ–° x_{t-1}

        final_samples = x_t
        save_image(final_samples, out_path, nrow=n_per_class, normalize=True)
    print(f"ğŸ’¾ Saved DPM samples to {out_path}")

# =====================================================
# E. è®­ç»ƒå¾ªç¯å’Œä¸»å‡½æ•° (Training Loop and Main)
# =====================================================

def run_training_session(model, optimizer, labeled_loader, unlabeled_loader, val_loader, cfg,
                         is_final_training=False, trial_id=None):
    total_epochs = cfg.final_epochs if is_final_training else cfg.optuna_epochs
    sample_dir = os.path.join(cfg.output_dir, "sample_progress")
    os.makedirs(sample_dir, exist_ok=True)

    metrics = {"Neg_ELBO": [], "DPM_Loss": [], "KLz": [], "NMI": [], "PosteriorAcc": [], "tau": []}
    best_val_nmi = -np.inf

    for epoch in range(1, total_epochs + 1):
        model.train()
        epoch_neg_elbo, epoch_dpm_loss = 0.0, 0.0
        
        # Tau Annealing
        if epoch > total_epochs * 0.5:
            cfg.current_gumbel_temp = max(cfg.min_gumbel_temp, cfg.current_gumbel_temp * cfg.gumbel_anneal_rate)

        # ç¡®ä¿ zip å¾ªç¯é•¿åº¦ä¸€è‡´ (ä»¥è¾ƒçŸ­çš„ä¸ºå‡†ï¼Œè¿™æ˜¯åŠç›‘ç£çš„å¸¸è§åšæ³•)
        for (x_lab, y_lab), (x_un, _) in zip(labeled_loader, unlabeled_loader):
            x_lab, y_lab = x_lab.to(cfg.device), y_lab.to(cfg.device).long()
            x_un = x_un.to(cfg.device)
            
            # ç›‘ç£æŸå¤±
            loss_lab, elbo_lab, recon_lab, kl_lab, _, _ = model(x_lab, cfg, y_lab)
            
            # æ— ç›‘ç£æŸå¤± (è¿”å› resp ç”¨äº EMA)
            loss_un, elbo_un, recon_un, kl_un, resp, _ = model(x_un, cfg, None)
            
            loss = loss_lab + cfg.alpha_unlabeled * loss_un

            optimizer.zero_grad()
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)
            optimizer.step()

            # è®°å½•æŒ‡æ ‡
            epoch_neg_elbo += (loss_lab.item() + loss_un.item()) / 2
            epoch_dpm_loss += (recon_lab + recon_un) / 2 # recon_lab/recon_un å¯¹åº” DPM_Loss

        # EMA update
        with torch.no_grad():
            if resp is not None:
                model.registered_pi.copy_(0.95 * model.registered_pi + 0.05 * resp.mean(0).detach())

        # ---- Evaluate ----
        posterior_acc, cluster2label, val_nmi = evaluate_model(model, val_loader, cfg)
        
        metrics["Neg_ELBO"].append(epoch_neg_elbo / len(labeled_loader))
        metrics["DPM_Loss"].append(epoch_dpm_loss / len(labeled_loader))
        metrics["KLz"].append(0.0)
        metrics["NMI"].append(val_nmi)
        metrics["PosteriorAcc"].append(posterior_acc)
        metrics["tau"].append(cfg.current_gumbel_temp)

        if val_nmi > best_val_nmi:
            best_val_nmi = val_nmi

        mode = "FINAL" if is_final_training else "OPTUNA"
        print(f"[{mode}] Epoch {epoch}/{total_epochs} | NMI={val_nmi:.4f} | Acc={posterior_acc:.4f} "
              f"| Ï„={cfg.current_gumbel_temp:.3f}")

        # ---- Save Samples ----
        if is_final_training and (epoch % 10 == 0 or epoch == total_epochs):
            sample_and_save_dpm(model.cond_denoiser, model.dpm_process, cfg.num_classes,
                                os.path.join(sample_dir, f"final_epoch{epoch:03d}.png"), cfg.device)
    
    # ä¿å­˜æœ€ç»ˆåéªŒæ˜ å°„
    with open(os.path.join(cfg.output_dir, "posterior_mapping.json"), "w") as f:
        json.dump(cluster2label, f, indent=2)
    print(f"âœ… Final posterior accuracy: {posterior_acc:.4f}")

    return best_val_nmi, metrics

def objective(trial):
    """Optuna ç›®æ ‡å‡½æ•°ï¼šæœ€å°åŒ– -NMI"""
    from common_dpm import Config
    cfg = Config()
    cfg.output_dir = "./mDPM_semi_optuna"
    
    # å»ºè®®çš„è¶…å‚æ•° (æ ¹æ® mVAE å’Œ DPM ç‰¹ç‚¹è°ƒæ•´)
    cfg.unet_base_channels = trial.suggest_categorical("base_channels", [32, 64])
    cfg.lambda_entropy = trial.suggest_float("lambda_entropy", 1.0, 10.0)
    cfg.lr = trial.suggest_float("lr", 1e-4, 5e-3, log=True)
    cfg.alpha_unlabeled = trial.suggest_float("alpha_unlabeled", 0.5, 2.0)
    
    model = mDPM_SemiSup(cfg).to(cfg.device)
    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)
    labeled_loader, unlabeled_loader, val_loader = get_semi_loaders(cfg)

    best_nmi, _ = run_training_session(model, optimizer, labeled_loader, unlabeled_loader, val_loader, cfg,
                                       is_final_training=False, trial_id=trial.number)
    return -best_nmi


def main():
    # 1. Optuna è¶…å‚æœç´¢
    study = optuna.create_study(direction="minimize", sampler=optuna.samplers.TPESampler(seed=42))
    print("--- Starting Optuna Hyperparameter Search ---")
    study.optimize(objective, n_trials=10)

    best_params = study.best_params
    print("\n--- Optuna Complete ---")
    print("Best Parameters:", best_params)

    # 2. æœ€ç»ˆè®­ç»ƒé…ç½®
    cfg = Config()
    for k, v in best_params.items():
        setattr(cfg, k, v)
    json.dump(best_params, open(os.path.join(cfg.output_dir, "mDPM_best_params.json"), "w"), indent=4)

    # 3. æœ€ç»ˆè®­ç»ƒ
    model = mDPM_SemiSup(cfg).to(cfg.device)
    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)
    labeled_loader, unlabeled_loader, val_loader = get_semi_loaders(cfg)

    print("\n--- Starting Final Training ---")
    final_nmi, metrics = run_training_session(model, optimizer, labeled_loader, unlabeled_loader, val_loader, cfg,
                                              is_final_training=True)
    torch.save(model.state_dict(), os.path.join(cfg.output_dir, "mDPM_best_model.pt"))

    # 4. å¯è§†åŒ–
    generate_visualizations(model, val_loader, metrics, cfg)
    print(f"âœ… Training and Visualization Complete. Final NMI: {final_nmi:.4f}")

if __name__ == "__main__":
    main()