# å¿«é€Ÿå…¥é—¨æŒ‡å—

## ğŸ“¦ æ–‡ä»¶æ¸…å•

1. **hmm_vae_complete.py** (26KB) - å®Œæ•´HMM-VAEå®ç°
   - ConditionalVAE: æ¡ä»¶VAEæ¨¡å‹
   - HMM_ForwardBackward: Forward-Backwardé‡‡æ ·
   - EM_Trainer: EMè®­ç»ƒæ¡†æ¶
   - Visualizer: å¯è§†åŒ–å·¥å…·

2. **data_downloader.py** (6.7KB) - æ•°æ®ä¸‹è½½è„šæœ¬
   - ä½¿ç”¨akshareä¸‹è½½CSI500æ•°æ®
   - æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†
   - æ”¶ç›Šç‡è®¡ç®—

3. **run_experiment.py** (16KB) - å®Œæ•´å®éªŒè„šæœ¬
   - TradingStrategy: ä¸¤ç§äº¤æ˜“ç­–ç•¥
   - å›æµ‹åˆ†æ
   - ç»©æ•ˆè¯„ä¼°

4. **code_review.md** (11KB) - ä»£ç å®¡æŸ¥æŠ¥å‘Š
   - æ‚¨åŸä»£ç çš„é—®é¢˜åˆ†æ
   - ä¸è®ºæ–‡çš„å¯¹æ¯”

5. **README.md** (8.6KB) - è¯¦ç»†æ–‡æ¡£
   - æ¨¡å‹æ¶æ„è¯´æ˜
   - è¶…å‚æ•°è°ƒä¼˜
   - å¸¸è§é—®é¢˜

---

## ğŸš€ 30ç§’å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1: ç›´æ¥è¿è¡Œ(ä½¿ç”¨ç¤ºä¾‹æ•°æ®)

```bash
python run_experiment.py
```

è¿™å°†:
- âœ… ç”Ÿæˆæ¨¡æ‹Ÿçš„CSI500æ•°æ®
- âœ… è®­ç»ƒHMM-VAEæ¨¡å‹(100 epochs)
- âœ… æ‰§è¡Œä¸¤ç§äº¤æ˜“ç­–ç•¥å›æµ‹
- âœ… ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–ç»“æœ

**è¾“å‡ºæ–‡ä»¶**:
- `training_curves.png` - è®­ç»ƒæ›²çº¿
- `transition_matrix.png` - çŠ¶æ€è½¬ç§»çŸ©é˜µ
- `backtest_comparison.png` - å›æµ‹å¯¹æ¯”

---

### æ–¹æ³•2: ä½¿ç”¨çœŸå®CSI500æ•°æ®

```bash
# 1. å®‰è£…ä¾èµ–
pip install akshare torch numpy pandas matplotlib seaborn scikit-learn

# 2. ä¸‹è½½æ•°æ®
python data_downloader.py

# 3. è¿è¡Œå®éªŒ
python run_experiment.py
```

---

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

ç¼–è¾‘`run_experiment.py`ä¸­çš„config:

```python
config = {
    'seq_len': 30,          # åºåˆ—é•¿åº¦(å¤©)
    'latent_dim': 12,       # æ½œå˜é‡ç»´åº¦
    'n_states': 3,          # HMMçŠ¶æ€æ•°
    'batch_size': 128,      # æ‰¹å¤§å°
    'n_epochs': 100,        # è®­ç»ƒè½®æ•°
    'temperature_start': 5.0,   # Gumbelåˆå§‹æ¸©åº¦
    'temperature_end': 0.5      # Gumbelæœ€ç»ˆæ¸©åº¦
}
```

---

## ğŸ“Š é¢„æœŸè¾“å‡º

### 1. æ§åˆ¶å°è¾“å‡º

```
>>> é˜¶æ®µ1: æ•°æ®å‡†å¤‡
æ•°æ®å½¢çŠ¶: (1000, 500)

>>> é˜¶æ®µ2: æ¨¡å‹è®­ç»ƒ
è®­ç»ƒé›†: (800, 30, 500), æµ‹è¯•é›†: (200, 30, 500)

Epoch  20 | Recon: 0.0234 | KLD: 2.1456 | HMM: 145.3 | Temp: 4.56
Epoch  40 | Recon: 0.0198 | KLD: 1.8923 | HMM: 132.7 | Temp: 3.72
...

>>> é˜¶æ®µ3: ç­–ç•¥å›æµ‹

### ç­–ç•¥1: çŠ¶æ€æ‹©æ—¶ ###
è¯†åˆ«çš„ç‰›å¸‚çŠ¶æ€: 1
State 0: å¹³å‡æ”¶ç›Š = -0.12%
State 1: å¹³å‡æ”¶ç›Š = 0.34%
State 2: å¹³å‡æ”¶ç›Š = 0.05%

çŠ¶æ€æ‹©æ—¶ ç»©æ•ˆæŒ‡æ ‡:
  æ€»æ”¶ç›Šç‡:        15.43%
  å¹´åŒ–æ”¶ç›Šç‡:      12.87%
  å¤æ™®æ¯”ç‡:        0.9234
  æœ€å¤§å›æ’¤:        -8.56%
  èƒœç‡:            58.32%

### ç­–ç•¥2: å¤šç©ºå¯¹å†² ###
  æ€»æ”¶ç›Šç‡:        22.18%
  å¹´åŒ–æ”¶ç›Šç‡:      18.45%
  å¤æ™®æ¯”ç‡:        1.2156
  æœ€å¤§å›æ’¤:        -6.23%
  èƒœç‡:            61.45%
```

### 2. ç”Ÿæˆçš„å›¾è¡¨

**training_curves.png**:
- VAEé‡å»ºæŸå¤±æ›²çº¿
- KLæ•£åº¦æ›²çº¿
- HMMè´Ÿå¯¹æ•°ä¼¼ç„¶æ›²çº¿

**transition_matrix.png**:
```
         State 0  State 1  State 2
State 0   0.82     0.12     0.06
State 1   0.10     0.78     0.12
State 2   0.08     0.10     0.82
```

**backtest_comparison.png**:
- å‡€å€¼æ›²çº¿å¯¹æ¯”
- æ”¶ç›Šç‡åˆ†å¸ƒ
- å›æ’¤æ›²çº¿
- çŠ¶æ€æ—¶åº

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q: CUDA out of memory

**A**: å‡å°batch_size
```python
config = {
    'batch_size': 32,  # ä»128é™åˆ°32
    ...
}
```

### Q: çŠ¶æ€å…¨éƒ¨é¢„æµ‹ä¸ºåŒä¸€ä¸ª

**A**: çŠ¶æ€åç¼©,è°ƒæ•´æ¸©åº¦å’Œæ­£åˆ™åŒ–
```python
# åœ¨hmm_vae_complete.pyçš„EM_Trainer.em_stepä¸­æ·»åŠ :
# è®¡ç®—çŠ¶æ€åˆ†å¸ƒç†µ
state_dist = sampled_states.mean(dim=0).mean(dim=0)
entropy = -(state_dist * torch.log(state_dist + 1e-9)).sum()
entropy_loss = -0.1 * entropy  # é¼“åŠ±çŠ¶æ€å‡åŒ€åˆ†å¸ƒ

total_loss = vae_loss + hmm_loss + entropy_loss
```

### Q: VAEé‡å»ºè´¨é‡å·®

**A**: å¢åŠ æ¨¡å‹å®¹é‡
```python
vae = ConditionalVAE(
    input_dim=n_stocks,
    latent_dim=16,      # ä»8å¢åŠ åˆ°16
    n_states=config['n_states'],
    hidden_dim=512      # ä»256å¢åŠ åˆ°512
)
```

---

## ğŸ¯ ä¸‹ä¸€æ­¥

### 1. è¶…å‚æ•°ä¼˜åŒ–

ä½¿ç”¨Optunaè‡ªåŠ¨æœç´¢æœ€ä½³å‚æ•°:

```python
import optuna

def objective(trial):
    config = {
        'latent_dim': trial.suggest_int('latent_dim', 4, 16),
        'n_states': trial.suggest_int('n_states', 2, 5),
        'temperature_end': trial.suggest_float('temp_end', 0.1, 1.0)
    }
    
    # è®­ç»ƒå¹¶è¯„ä¼°
    vae, hmm, results = train_and_evaluate(config)
    
    return results['strategy1']['metrics']['sharpe']

study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=50)
```

### 2. æ·»åŠ é£é™©ç®¡ç†

```python
# åœ¨TradingStrategyä¸­
def strategy_with_risk_control(self, test_data, real_returns, max_drawdown=-0.15):
    nav = 1.0
    for i in range(len(test_data)):
        # æ£€æŸ¥å½“å‰å›æ’¤
        current_dd = (nav - peak_nav) / peak_nav
        if current_dd < max_drawdown:
            # å¼ºåˆ¶å¹³ä»“
            position = 0
        else:
            # æ­£å¸¸äº¤æ˜“
            ...
```

### 3. é›†æˆå¤šä¸ªæ¨¡å‹

```python
# Ensemble: è®­ç»ƒå¤šä¸ªHMM-VAE,æŠ•ç¥¨å†³ç­–
models = [train_hmm_vae(config, seed=i) for i in range(5)]

def ensemble_predict(models, y_seq):
    states = [model.predict_state(y_seq) for model in models]
    return max(set(states), key=states.count)  # å¤šæ•°æŠ•ç¥¨
```

---

## ğŸ“š å­¦ä¹ è·¯å¾„

1. **ç†è§£è®ºæ–‡**: é˜…è¯»README.mdä¸­çš„æ¨¡å‹æ¶æ„éƒ¨åˆ†
2. **ä»£ç å®¡æŸ¥**: æŸ¥çœ‹code_review.md,å¯¹æ¯”æ‚¨çš„ä»£ç 
3. **è¿è¡Œå®éªŒ**: æ‰§è¡Œrun_experiment.py,è§‚å¯Ÿç»“æœ
4. **è°ƒæ•´å‚æ•°**: ä¿®æ”¹config,å°è¯•ä¸åŒé…ç½®
5. **æ”¹è¿›ç­–ç•¥**: å®ç°æ›´å¤æ‚çš„äº¤æ˜“é€»è¾‘

---

## ğŸ’¡ æç¤º

- è®­ç»ƒ100 epochsåœ¨CPUä¸Šçº¦éœ€20-30åˆ†é’Ÿ
- GPUå¯åŠ é€Ÿè‡³5-10åˆ†é’Ÿ
- é¦–æ¬¡è¿è¡Œå»ºè®®ä½¿ç”¨ç¤ºä¾‹æ•°æ®,å¿«é€ŸéªŒè¯ä»£ç 
- çœŸå®æ•°æ®ä¸‹è½½å¯èƒ½éœ€è¦10-30åˆ†é’Ÿ(å–å†³äºç½‘ç»œ)

---

## ğŸ“ è·å–å¸®åŠ©

é‡åˆ°é—®é¢˜? æ£€æŸ¥:
1. README.md - è¯¦ç»†æ–‡æ¡£
2. code_review.md - å¸¸è§é”™è¯¯
3. ä»£ç æ³¨é‡Š - æ¯ä¸ªå‡½æ•°éƒ½æœ‰è¯´æ˜

ç¥æ‚¨å®éªŒé¡ºåˆ©! ğŸ‰
