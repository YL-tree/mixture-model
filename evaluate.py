import torch
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
from common_dpm import Config
from mDPM import mDPM_SemiSup, evaluate_model # ç¡®ä¿å¼•ç”¨æ­£ç¡®

def verify_model_performance(model_path="mDPM_results_semisupervised/best_model.pt"):
    # 1. å‡†å¤‡é…ç½®å’Œç¯å¢ƒ
    cfg = Config()
    device = cfg.device
    print(f"ğŸ” Loading model from {model_path}...")

    # 2. åŠ è½½æ¨¡å‹
    model = mDPM_SemiSup(cfg).to(device)
    try:
        checkpoint = torch.load(model_path, map_location=device)
        # å…¼å®¹åªä¿å­˜äº† state_dict æˆ–ä¿å­˜äº†å®Œæ•´ checkpoint çš„æƒ…å†µ
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return

    model.eval()

    # 3. åŠ è½½çœŸæ­£çš„ Test Set (10k images)
    print("ğŸ“¦ Loading MNIST Test Set...")
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)

    # 4. è¿è¡Œè¯„ä¼° (å¤ç”¨ä½ ç°æœ‰çš„ evaluate_model)
    # æ³¨æ„ï¼ševaluate_model å†…éƒ¨ä¼šè·‘ t=500 çš„é‡‡æ ·ï¼Œæ¯”è¾ƒæ…¢ï¼Œè¯·è€å¿ƒç­‰å¾…
    print("ğŸš€ Running inference on Test Set (this may take a while)...")
    acc, cluster2label, nmi = evaluate_model(model, test_loader, cfg)

    print("\n" + "="*40)
    print(f"âœ… Final Test Results:")
    print(f"   Accuracy (ACC): {acc*100:.2f}%")
    print(f"   NMI Score:      {nmi:.4f}")
    print("="*40 + "\n")

    # 5. (å¯é€‰) ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    # ä¸ºäº†ç”»æ··æ·†çŸ©é˜µï¼Œæˆ‘ä»¬éœ€è¦æ‹¿åˆ°åŸå§‹çš„ preds å’Œ targets
    # è¿™é‡Œç®€å•é‡æ–°æ‰‹åŠ¨è·‘ä¸€éè·å–æ•°æ®ï¼ˆä¸ºäº†ä»£ç ç‹¬ç«‹æ€§ï¼‰
    print("ğŸ¨ Generating Confusion Matrix...")
    all_preds = []
    all_targets = []
    
    # ç®€åŒ–ç‰ˆå¿«é€Ÿæ¨ç† (åªç”¨ t=500, repeat=1)
    with torch.no_grad():
        for x, y in test_loader:
            x = x.to(device)
            batch_size = x.size(0)
            
            # å¿«é€Ÿé¢„æµ‹ï¼šåªé‡‡æ ·ä¸€æ¬¡ï¼Œt=500
            t_val = 500
            t = torch.full((batch_size,), t_val, device=device, dtype=torch.long)
            noise = torch.randn_like(x)
            x_t = model.dpm_process.q_sample(x, t, noise)
            
            mse_scores = []
            for k in range(cfg.num_classes):
                y_vec = torch.nn.functional.one_hot(torch.full((batch_size,), k, device=device), cfg.num_classes).float()
                pred = model.cond_denoiser(x_t, t, y_vec)
                loss = torch.nn.functional.mse_loss(pred, noise, reduction='none').view(batch_size, -1).mean(dim=1)
                mse_scores.append(loss.unsqueeze(1))
            
            mse_scores = torch.cat(mse_scores, dim=1) # (B, 10)
            raw_preds = torch.argmin(mse_scores, dim=1).cpu().numpy()
            
            # ä½¿ç”¨ evaluate_model ç®—å‡ºæ¥çš„æ˜ å°„å…³ç³»å¯¹é½æ ‡ç­¾
            aligned_preds = [cluster2label.get(p, p) for p in raw_preds]
            
            all_preds.extend(aligned_preds)
            all_targets.extend(y.numpy())

    # ç»˜åˆ¶
    cm = confusion_matrix(all_targets, all_preds)
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')
    plt.title(f'Confusion Matrix (Acc: {acc:.2%})')
    plt.savefig('confusion_matrix_test.png')
    print("ğŸ’¾ Confusion matrix saved to 'confusion_matrix_test.png'")

if __name__ == "__main__":
    verify_model_performance()