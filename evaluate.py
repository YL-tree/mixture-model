import torch
import os
import json
import numpy as np
import torch.nn.functional as F
from scipy.optimize import linear_sum_assignment
from sklearn.metrics import normalized_mutual_info_score as NMI

# å¯¼å…¥ä½ çš„æ¨¡åž‹å®šä¹‰
from common_dpm import Config, get_semi_loaders
from mDPM import mDPM_SemiSup  # ç¡®ä¿ mDPM.py ä¸­åŒ…å« mDPM_SemiSup ç±»

# ==========================================
# æ ¸å¿ƒè¯„ä¼°å‡½æ•° (åŒ…å« Low-T å’Œ Monte Carlo ç­–ç•¥)
# ==========================================

import torch
import os
import json
import numpy as np
import torch.nn.functional as F
from scipy.optimize import linear_sum_assignment
from sklearn.metrics import normalized_mutual_info_score as NMI

from common_dpm import Config, get_semi_loaders
from mDPM import mDPM_SemiSup 

def robust_evaluate(model, loader, cfg):
    """
    V4 ç»ˆæžè¯„ä¼°ç‰ˆï¼šå…¨è½¨è¿¹æ‰«æ (Full Trajectory Density Scan)
    æ—¢ç„¶ä¿¡å·å¾®å¼±ï¼Œæˆ‘ä»¬å°±é€šè¿‡è¦†ç›–æ›´å¤šçš„æ—¶é—´æ­¥æ¥ç§¯ç´¯è¯æ® (Accumulate Evidence)ã€‚
    """
    model.eval()
    preds, ys_true = [], []
    
    # [æ ¸å¿ƒä¿®æ”¹] ä¸å†çŒœå“ªä¸ªæ—¶é—´æ­¥å¥½ï¼Œè€Œæ˜¯å‡åŒ€æ‰«æ 20-50 ä¸ªç‚¹
    # è¦†ç›–ä»Žæ¸…æ™°(t=50)åˆ°æ¨¡ç³Š(t=950)çš„å…¨è¿‡ç¨‹
    # æ—¢ç„¶æ˜¯ä¸€æ¬¡æ€§è¯„ä¼°ï¼Œç¨å¾®æ…¢ç‚¹æ²¡å…³ç³»ï¼Œå‡†ç¡®çŽ‡æœ€é‡è¦
    eval_timesteps = torch.linspace(50, 950, 30).long().tolist() 
    
    print(f"ðŸš€ å¯åŠ¨å…¨è½¨è¿¹æ‰«æè¯„ä¼°: æ‰«æ {len(eval_timesteps)} ä¸ªæ—¶é—´ç‚¹...")

    with torch.no_grad():
        for i, (x_0, y_true) in enumerate(loader):
            x_0 = x_0.to(cfg.device)
            batch_size = x_0.size(0)
            
            # (Batch, 10) - ç”¨äºŽç´¯ç§¯æ‰€æœ‰æ—¶é—´æ­¥çš„ MSE
            cumulative_mse = torch.zeros(batch_size, cfg.num_classes, device=cfg.device)
            
            # æ‰«ææ¯ä¸€ä¸ªæ—¶é—´æ­¥
            for t_val in eval_timesteps:
                # æ¯ä¸ªæ—¶é—´æ­¥é‡‡æ · 1 æ¬¡å™ªå£°å³å¯ï¼Œå› ä¸ºæˆ‘ä»¬æ‰«äº† 30 ä¸ªæ—¶é—´æ­¥ï¼Œ
                # è¿™æœ¬èº«å°±æ˜¯ä¸€ç§å¼ºå¤§çš„ Monte Carlo å¹³å‡
                noise = torch.randn_like(x_0)
                current_t = torch.full((batch_size,), t_val, device=cfg.device, dtype=torch.long)
                x_t = model.dpm_process.q_sample(x_0, current_t, noise)
                
                # è®¡ç®— 10 ä¸ªç±»åˆ«çš„ Loss
                for k in range(cfg.num_classes):
                    y_vec = F.one_hot(torch.full((batch_size,), k, device=x_0.device), cfg.num_classes).float()
                    
                    pred_noise = model.cond_denoiser(x_t, current_t, y_vec)
                    
                    # [å…³é”®] ä½¿ç”¨ sum è€Œä¸æ˜¯ meanï¼Œé¿å…æ•°å€¼è¿‡å° (è™½ç„¶æ•°å­¦ä¸Š argmin ä¸å˜ï¼Œä½†æ•°å€¼ç¨³å®šæ€§æ›´å¥½)
                    # view(B, -1).sum(dim=1)
                    loss = F.mse_loss(pred_noise, noise, reduction='none').view(batch_size, -1).sum(dim=1)
                    
                    cumulative_mse[:, k] += loss

            # é¢„æµ‹ MSE æœ€å°çš„ç±»åˆ« (Evidence æœ€å¤§)
            pred_cluster = torch.argmin(cumulative_mse, dim=1).cpu().numpy()
            
            preds.append(pred_cluster)
            ys_true.append(y_true.numpy())
            
            # if i % 5 == 0:
            #     acc_batch = (pred_cluster == y_true.numpy()).mean()
            #     print(f"   Batch {i}: å½“å‰ Batch å‡†ç¡®çŽ‡ {acc_batch:.4f}")

    preds = np.concatenate(preds)
    ys_true = np.concatenate(ys_true)
    
    # # æ—¢ç„¶æ˜¯å…¨ç›‘ç£ï¼ŒRaw Accuracy å°±æ˜¯çœŸå®žå‡†ç¡®çŽ‡
    # final_acc = np.mean(preds == ys_true)
    # nmi = NMI(ys_true, preds)
    
    # return final_acc, final_acc, nmi, {}
    
    # --- æŒ‡æ ‡è®¡ç®— ---
    nmi = NMI(ys_true, preds)
    
    # åŒˆç‰™åˆ©ç®—æ³•å¯¹é½ (å“ªæ€•æ˜¯å…¨ç›‘ç£ä¹Ÿå¯ä»¥è·‘ä¸€ä¸‹ï¼Œç¡®è®¤æ˜¯å¦å¯¹é½)
    n_classes = cfg.num_classes
    cost_matrix = np.zeros((n_classes, n_classes))
    for i in range(n_classes):
        for j in range(n_classes):
            cost_matrix[i, j] = -np.sum((ys_true == i) & (preds == j))
            
    row_ind, col_ind = linear_sum_assignment(cost_matrix)
    cluster2label = {int(c): int(l) for c, l in zip(col_ind, row_ind)}
    aligned_preds = np.array([cluster2label.get(p, 0) for p in preds])
    
    # åŽŸå§‹å‡†ç¡®çŽ‡ (å‡è®¾ç±»åˆ« ID ä¸€ä¸€å¯¹åº”)
    raw_acc = np.mean(preds == ys_true)
    # å¯¹é½åŽå‡†ç¡®çŽ‡
    posterior_acc = np.mean(aligned_preds == ys_true)
    
    return raw_acc, posterior_acc, nmi, cluster2label

# ==========================================
# ä¸»åŠ è½½é€»è¾‘
# ==========================================
def load_and_run():
    # 1. åˆå§‹åŒ–é…ç½®
    cfg = Config()
    
    # [é‡è¦] å¿…é¡»ä¸Žè®­ç»ƒæ—¶çš„é…ç½®ä¸€è‡´ï¼Œå¦åˆ™æ¨¡åž‹æƒé‡åŠ è½½ä¼šæŠ¥é”™
    # å¦‚æžœä½ åœ¨è®­ç»ƒæ—¶ä¿®æ”¹äº† batch_size æˆ– channelsï¼Œè¿™é‡Œä¹Ÿè¦æ”¹
    cfg.unet_base_channels = 64  # è¯·ç¡®è®¤ä½ è®­ç»ƒæ—¶æ˜¯ç”¨ 32 è¿˜æ˜¯ 64
    cfg.batch_size = 32          # è¯„ä¼°æ—¶ Batch å¯ä»¥å°ä¸€ç‚¹ä»¥é˜²æ˜¾å­˜æº¢å‡º
    
    # æ¨¡åž‹è·¯å¾„
    model_path = os.path.join(cfg.output_dir, "mDPM_best_model.pt") 
    # æˆ–è€…å¦‚æžœä½ æ˜¯åœ¨å…¨ç›‘ç£æ–‡ä»¶å¤¹ä¸‹ï¼š
    # model_path = "./mDPM_results_supervised/mDPM_best_model.pt" 
    
    if not os.path.exists(model_path):
        print(f"âŒ æ‰¾ä¸åˆ°æ¨¡åž‹æ–‡ä»¶: {model_path}")
        return

    print(f"ðŸ“‚ æ­£åœ¨åŠ è½½æ¨¡åž‹: {model_path}")
    print(f"âš™ï¸  è®¾å¤‡: {cfg.device}")

    # 2. åˆå§‹åŒ–æ¨¡åž‹æž¶æž„
    model = mDPM_SemiSup(cfg).to(cfg.device)
    
    # 3. åŠ è½½æƒé‡
    try:
        checkpoint = torch.load(model_path, map_location=cfg.device)
        model.load_state_dict(checkpoint)
        print("âœ… æ¨¡åž‹æƒé‡åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")
        print("æç¤ºï¼šè¯·æ£€æŸ¥ cfg.unet_base_channels æ˜¯å¦ä¸Žè®­ç»ƒæ—¶ä¸€è‡´ã€‚")
        return

    # 4. èŽ·å–éªŒè¯é›†æ•°æ®
    # get_semi_loaders è¿”å›ž (labeled, unlabeled, val_loader)
    _, _, val_loader = get_semi_loaders(cfg)
    
    # 5. è¿è¡Œè¯„ä¼°
    print("\nðŸš€ å¼€å§‹è¿è¡Œ Robust Evaluate...")
    raw_acc, post_acc, nmi, mapping = robust_evaluate(model, val_loader, cfg)
    
    print("\n" + "="*30)
    print(f"ðŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æžœ")
    print("="*30)
    print(f"Raw Accuracy (æ— å¯¹é½):  {raw_acc:.4f}")
    print(f"Aligned Accuracy (å¯¹é½åŽ): {post_acc:.4f}")
    print(f"NMI Score:              {nmi:.4f}")
    print("-" * 30)
    print(f"ç±»åˆ«æ˜ å°„ (Cluster -> Label): {mapping}")
    print("="*30)

if __name__ == "__main__":
    load_and_run()